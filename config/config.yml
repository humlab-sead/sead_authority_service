options:
  id_base: "https://w3id.org/sead/id/"
  auto_accept_threshold: 0.90
  default_query_limit: 10
  database:
    dbname: sead_staging

policy:
  site:
    proximity_boost:
      very_near_distance_km: 0.2
      to_far_distance_km: 10.0
    place_name_similarity_boost:
      similarity_threshold: 0.3
      max_boost: 0.1
  modification_type:
    lookup_format: "json"
    lookup_fields_map:
      id: "modification_type_id"
      label: "modification_type_name"
      description: "modification_type_description"
    entity_type_description: "modification type"
    roles: 
      - role: system
        content: You are archaeological specialist with expertise in identifying and classifying archaeological samples based on their features and characteristics.
    context: |
      You are provided with known modification types, each with an id, a label and a description.
    output:
      format: json
  geonames:
    options:
      username: "${GEONAMES_USERNAME}"
      lang: "en"
      country_bias: "en"
      fuzzy: 0.8
      feature_classes: ["P", "A"]  # Populated places and Administrative divisions
      orderby: "relevance"
      style: "FULL"

features:
  use_mcp_server: false  # Start disabled, flip to true when ready

mcp:
  version: "0.1.0"
  retrieval:
    k_fuzzy: 30        # Top-K from trigram search
    k_sem: 30          # Top-K from semantic search (Phase 3)
    k_final: 20        # Final candidate count
    min_score_threshold: 0.6  # Minimum score to return
  enable_caching: true
  cache_ttl_seconds: 86400
  embedding:
    model: "sentence-transformers/all-mpnet-base-v2"
    dimensions: 768

table_specs: "@include: entities.yml"

llm:
  provider: "openai"  # "openai" or "anthropic", "ollama"
  options:
    max_tokens: 10000
    temperature: 0.1
  enable_translation: true
  enable_semantic_matching: true
  translation_target_lang: "en"
  semantic_batch_size: 50
  openai:
    model: "gpt-4o-mini"  # "gpt-4o-mini"
    provider_id: "openapi"
    api_key: "${OPENAI_API_KEY}"
    options:
      temperature: 0.1
      max_tokens: 4096
      stream: false
      # messages: Iterable[ChatCompletionMessageParam],
      # max_completion_tokens: Optional[int] | Omit = omit,
      # max_tokens: Optional[int] | Omit = omit,
      # metadata: Optional[Metadata] | Omit = omit,
      # modalities: Optional[List[Literal["text", "audio"]]] | Omit = omit,
      # n: Optional[int] | Omit = omit,
      # prediction: Optional[ChatCompletionPredictionContentParam] | Omit = omit,
      # response_format: completion_create_params.ResponseFormat | Omit = omit,
      # seed: Optional[int] | Omit = omit,
      # stream: Optional[Literal[False]] | Omit = omit,
      # stream_options: Optional[ChatCompletionStreamOptionsParam] | Omit = omit,
      # temperature: Optional[float] | Omit = omit,
      # top_p: Optional[float] | Omit = omit,
      # user: str | Omit = omit,
      # verbosity: Optional[Literal["low", "medium", "high"]] | Omit = omit,
      # web_search_options: completion_create_params.WebSearchOptions | Omit = omit,
  ollama:
    provider_id: "ollama"
    model: "gpt-oss:20b"
    host: "${OLLAMA_BASE_URL}"
    timeout: 30
    options:
      temperature: 0.1
      # max_tokens: 9999
      num_predict: 4096
      #num_ctx
  anthropic:
    provider_id: "anthropic"
    model: "claude-2"  
    api_key: "${ANTHROPIC_API_KEY}"
    options:
      temperature: 0.1
      max_tokens: 1000
  prompts: "@include prompts.yml"

geonames:
  options:
    username: "${GEONAMES_USERNAME}"
    lang: "en"
    country_bias: "en"
    fuzzy: 0.8
    feature_classes: ["P", "A"]  # Populated places and Administrative divisions
    orderby: "relevance"
    style: "FULL"

logging:
  folder: ./logs
  handlers:
    - sink: "import_excel.log"
      level: "DEBUG"
      format: "{time} - {level} - {message}"
    - sink: "sys.stdout"
      level: "DEBUG"
      format: "{time} - {level} - {message}"
